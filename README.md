# EmailClassifierWithInterface
This classifier allows the user to copy and paste in an email text and get a level of confidence of its spam value

Libraries/Technologies Used:

Technologies: Python, Jupyter Notebooks

Libraries: Pytorch, SkLearn, Numpy, Pandas, NLTK, Gradio, CSV, JSON

Dataset from: https://github.com/hql5426/nlc-email-phishing

Dataset Info:
This dataset was generated by IBM of over 20,000 training email instances that included spam, phishing, and ham. This set was made up of ham from the Enron corpus, run of the mill promotional/pornographic spam, and some emails targeted at soliciting a response such as the “Nigerian prince” emails. It was designed to be used with a Watson application. See the dataset balance below using PyPlot.

Prepping:
The data was normalized using a series of regex functions to remove punctuation, capitalization, and other symbols that could confuse the model. Stopwords were then removed using the stopwords corpus from Python’s Natural Language Toolkit or NLTK for short. Each email body was then tokenized to split up the words into their own elements and provide an easier separation for the step of stemming or the act of distilling a word to its root meaning.

Feature Selection:
The words were then detokenized to be fed in to a tdif-vectorizer to mathematically represent each piece of text. All of these features were then trimmed via the SelectPercentile method in SkLearn.

Model Selection:
Logistic Regression, Random Forest, Naive Bayes, and Support Vector Machines were used as base models and each was combined after a short hyperparameter search in to a Voting Classifier. Each was evaluated using the Accuracy, AUC, and F1 Scores with the Voting Classifier performing at 0.99 in each category.

Shipping:
Each model (including the working vectorizer and feature selector) were pickled to preserve their trained states. Each was accessed using the Python library, Gradio. Due to time contraints and performance concerns (the Random Forest, SVM, and Voting Classifiers ran quite slowly), the logistic regression model was used as the demonstration model and shipped to "production" with Gradio. 

Unfortunately, my pickles were not able to be uploaded due to file size constraints on GitHub so the code is uploaded but the display functions may not work. I will upload a zip file to include everything in case anyone wants to use it.
